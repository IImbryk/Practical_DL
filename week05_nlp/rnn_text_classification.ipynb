{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88122f2c",
   "metadata": {},
   "source": [
    "Задача классификации комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from nltk import word_tokenize \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae476a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"comments.tsv\", sep='\\t')\n",
    "\n",
    "texts = data['comment_text'].values\n",
    "target = data['should_ban'].values\n",
    "\n",
    "SEED = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0f479",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df56311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=SEED, stratify=data['should_ban'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7e630",
   "metadata": {},
   "source": [
    "### My dataset (to pytorch format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels.iloc[idx]\n",
    "        text = self.text.iloc[idx]\n",
    "        sample = [label, text]\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = CustomTextDataset(train['comment_text'], train['should_ban'])\n",
    "test_dataset = CustomTextDataset(test['comment_text'], test['should_ban'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be37fd",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = train_dataset\n",
    "\n",
    "def yield_tokens(datasets):\n",
    "    for dataset in datasets:\n",
    "        for _, text in dataset:\n",
    "            yield tokenizer(text)\n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokens([train_dataset, test_dataset]), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156c49c",
   "metadata": {},
   "source": [
    "#### example tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"Hello how are you?, Welcome to CoderzColumn!!\")\n",
    "indexes = vocab(tokens)\n",
    "\n",
    "tokens, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[510, 'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f84474",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset:\n",
    "    vocab(tokenizer(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab(tokenizer(text)) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
    "\n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(Y)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset , batch_size=1024, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, Y in train_loader:\n",
    "    print(X.shape, Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1155d53",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "embed_len = 50\n",
    "hidden_dim = 50\n",
    "n_layers = 2\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
    "        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        embeddings = self.embedding_layer(X_batch)\n",
    "        output, hidden = self.rnn(embeddings, torch.randn(n_layers, len(X_batch), hidden_dim))\n",
    "        return self.linear(output[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_classifier = RNNClassifier()\n",
    "\n",
    "rnn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03add661",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in rnn_classifier.children():\n",
    "    print(\"Layer : {}\".format(layer))\n",
    "    print(\"Parameters : \")\n",
    "    for param in layer.parameters():\n",
    "        print(param.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361427fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rnn_classifier(torch.randint(0, len(vocab), (1024, max_words)))\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93595b6c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39757df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
    "\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            Y_preds = model(X)\n",
    "\n",
    "            loss = loss_fn(Y_preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        CalcValLossAndAccuracy(model, loss_fn, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "epochs = 150\n",
    "learning_rate = 1e-4\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "rnn_classifier = RNNClassifier()\n",
    "optimizer = AdamW(rnn_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(rnn_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePredictions(model, loader):\n",
    "    Y_shuffled, Y_preds = [], []\n",
    "    for X, Y in loader:\n",
    "        preds = model(X)\n",
    "        Y_preds.append(preds)\n",
    "        Y_shuffled.append(Y)\n",
    "    gc.collect()\n",
    "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
    "\n",
    "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "\n",
    "Y_actual, Y_preds = MakePredictions(rnn_classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dac827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(Y_actual, Y_preds, target_names=['0', '1']))\n",
    "print(\"\\nConfusion Matrix : \")\n",
    "print(confusion_matrix(Y_actual, Y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55090b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# for name, X, y, model in [\n",
    "#     ('train', X_train_bow, y_train, bow_model),\n",
    "#     ('test ', X_test_bow, y_test, bow_model)\n",
    "# ]:\n",
    "auc = roc_auc_score(Y_actual, Y_preds)\n",
    "plt.plot(*roc_curve(Y_actual, Y_preds)[:2], label='AUC=%.4f' % (auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color='black',)\n",
    "plt.legend(fontsize='large')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56777a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
