{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b6e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import efficientnet_v2_s, resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11faab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array((0.4914, 0.4822, 0.4465))\n",
    "stds = np.array((0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_augment = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation([-30, 30]),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "    transforms.ColorJitter(brightness=0.02, contrast=0.001, saturation=0.2), # Set the color params\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, stds),\n",
    "])\n",
    "\n",
    "\n",
    "transform_augment_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, stds)])\n",
    "\n",
    "batch_size = 400\n",
    "\n",
    "\n",
    "train_loader = CIFAR10(\"./cifar_data/\", train=True, transform=transform_augment)\n",
    "trainloader = torch.utils.data.DataLoader(train_loader, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2)\n",
    "\n",
    "\n",
    "test_loader = CIFAR10(\"./cifar_data/\", train=False, transform=transform_augment_test)\n",
    "testloader = torch.utils.data.DataLoader(test_loader, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False, \n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82138288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "examples = next(iter(trainloader))\n",
    "\n",
    "img = examples[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(img[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db59d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "from models import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_loader.classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1, weight = None):\n",
    "        \"\"\"if smoothing == 0, it's one-hot method\n",
    "           if 0 < smoothing < 1, it's smooth method\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        assert 0 <= self.smoothing < 1\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            pred = pred * self.weight.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deadcfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "# model = ResNet9(3, 10).to(device)\n",
    "\n",
    "model = resnet18(weights='DEFAULT')\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.001) # 0.001 !\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr= 0.001, weight_decay=weight_decay) # 0.001 !\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = LabelSmoothingCrossEntropy(classes=num_classes, smoothing=0.3, dim=-1, weight = None)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "model, optimizer = train_model(model, criterion, \n",
    "                    optimizer, train_dataloader=trainloader, test_dataloader=testloader, \n",
    "                    device=device,\n",
    "                    n_epochs=100, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()}\n",
    "torch.save(checkpoint, 'resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1edd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
