{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Efficientnet_v2_s из коробки \n",
    "- LabelSmoothingCrossEntropy помогло повысить качество\n",
    "- При подготовке изображений используется нормализация схожая, но не точно такая же как в ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fbq3w_elNN12"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "import torch, sys, os, pdb\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import efficientnet_v2_s, resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhT-HC7nOQ-L"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "LR = 0.01\n",
    "N_EPOCH = 200\n",
    "batch_size = 128\n",
    "\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voMmXJSwOYd2"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomCrop(IMG_SIZE, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_-cg2guOhYx"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1, weight = None):\n",
    "        \"\"\"if smoothing == 0, it's one-hot method\n",
    "           if 0 < smoothing < 1, it's smooth method\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        assert 0 <= self.smoothing < 1\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            pred = pred * self.weight.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgFvlgcWOjvA"
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "        gt = []\n",
    "        net_outputs = []\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward and backward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        gt.extend(labels.data.cpu().numpy())\n",
    "                        net_outputs.extend(preds_class.data.cpu().numpy())\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "\n",
    "            if phase == 'train':\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                bacc = balanced_accuracy_score(gt, net_outputs)\n",
    "                print('{} Loss: {:.4f}, balanced_accuracy_score: {:.4f}, accuracy_score: {:.4f}'.format(phase, epoch_loss, bacc, accuracy_score(gt, net_outputs)), flush=True)\n",
    "\n",
    "            if phase == 'val' and bacc >= best_acc:\n",
    "                best_acc = bacc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_OMAiSRPJl2",
    "outputId": "86ccba01-53c3-4667-9a24-9664f43ecb00"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transforms)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "num_classes = len(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zQYOurCW-uE",
    "outputId": "3e09447c-095a-4abf-8eaf-51c31cfac45d"
   },
   "outputs": [],
   "source": [
    "net = efficientnet_v2_s(weights='DEFAULT')\n",
    "num_ftrs = net.classifier[1].in_features\n",
    "net.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX3S9R4nc8De"
   },
   "outputs": [],
   "source": [
    "# net = resnet18(weights='DEFAULT')\n",
    "# num_ftrs = net.fc.in_features\n",
    "# net.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj_lxB-GLQjF",
    "outputId": "1de5769b-0a5f-4f18-b9ab-5f786af7414a"
   },
   "outputs": [],
   "source": [
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "loss = LabelSmoothingCrossEntropy(classes=num_classes, smoothing=0.3, dim=-1, weight = None)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCH, verbose=True)\n",
    "\n",
    "model, best_acc = train_model(net, loss, optimizer, scheduler, num_epochs=N_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавить сохранение optimizer\n",
    "checkpoint = {\n",
    "    'model': model.state_dict()}\n",
    "torch.save(checkpoint, 'efficientnet_best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEosSKVfPUgc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
